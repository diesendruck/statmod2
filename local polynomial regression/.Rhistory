#   hyperparams: A vector of three hyperparameters, (b, tau1^2, tau2^2)
#   Y: A flag with Y values, used to add diagonal error variance to
#     covariance matrix, and to compute posterior mean.
#
# Returns:
#   z: The values produced by the Gaussian Process. If Y is provided for
#     posterior mean and covariance, then z is a matrix with a column
#     for posterior mean, and another for posterior covariance.
# Compute covariance matrix and use it to get GP values/output.
c <- Cov(inputs, inputs, hyperparams, kernel)
# ------ Posterior Calculations (Y!=NULL) ------ #
if (!is.null(Y)) {
# Compute K(X,X)+sigsq*I.
error.variance <- diag(rep(var(Y), dim(c)[1]))
c <- c + error.variance
# Make storage for posterior means and covariances.
posterior.mean.and.cov <- matrix(0, nrow=length(inputs), ncol=2)
# For each point, compute posterior mean and covariance.
n <- length(inputs)
for (i in 1:n) {
# Compute posterior mean = K(X*,X) %*% (K(X,X)+sigsq*I)^(-1) %*% y
k.xs.x <- as.matrix(Cov(inputs[i], inputs, hyperparams, kernel))
post.mean.i <- Y[i] + k.xs.x%*%ginv(c)%*%(Y-mean(Y))
post.cov.i <- Cov(inputs[i], inputs[i], hyperparams, kernel) - k.xs.x%*%ginv(c)%*%t(k.xs.x)
posterior.mean.and.cov[i,] <- c(post.mean.i, post.cov.i)
}
z <- posterior.mean.and.cov
return (z)
}
# ------ Regular Calculations (Y=NULL) ------ #
if (is.null(Y)) {
n <- length(inputs)
u <- rnorm(n)
decomp <- svd(c)
z <- decomp$u %*% sqrt(diag(decomp$d)) %*% u
# Plot the output.
plot(inputs, z, main=paste("b=", hyperparams[1],
" t1.sq=", hyperparams[2],
" t2.sq=", hyperparams[3]))
lines(inputs, z)
hist(z, 40)
return (z)
}
}
Cov <- function(ins, inputs, hyperparams, kernel) {
# Computes the covariance of a finite set of points.
#
# Args:
#   ins: The vector of points compared to inputs for covariance.
#   inputs: The vector of scalar points of the data.
#   hyperparams: A vector of three hyperparameters, (b, tau1^2, tau2^2)
#
# Returns:
#   cov.matrix: A symmetrix, positive semi-definite covariance matrix. The
#     dimensions of this matrix are: length(ins) x length(inputs)
b <- hyperparams[1]
t1.sq <- hyperparams[2]
t2.sq <- hyperparams[3]
# Compute covariance with specific covariance function.
cov.matrix <- matrix(NA, nrow=length(ins), ncol=length(inputs))
n1 <- length(ins)
n2 <- length(inputs)
for (i in 1:n1) {
for (j in 1:n2) {
cov.matrix[i, j] <- kernel(ins[i], inputs[j], b, t1.sq, t2.sq)
}
}
return (cov.matrix)
#   cov <- as.matrix(t(sapply(
#     ins, function(k) kernel(k, inputs, b, t1.sq, t2.sq))))
#   return (cov)
}
GetData <- function() {
# Prepares data from file.
#
# Args:
#   NA: None.
#
# Returns:
#   data: A matrix of data.
setwd("~/Google Drive/2. SPRING 2015/STAT MOD 2 - Prof Scott/local polynomial regression")
data <- read.csv("utilities.csv", header=T, sep=",")
# Add column for average daily bill.
data <- within(data, {
y <- gasbill/billingdays
x <- temp
})
data <- data[order(data[, 1]), ]
attach(data)
plot(x, y)
return (data)
}
PerformLOOCV <- function(data, bandwidth) {
# Computes hat matrix and LOOCV score for a given bandwidth; or, if no
# bandwidth is chosen, finds optimal bandwidth (one with lowest LOOCV score)
# and then computes hat matrix.
#
# Args:
#   data: The full data set.
#   bandwidth: The bandwidth for the model. Find optimal by leaving NULL.
#
# Returns:
#   hat.bw.score: A list of hat matrix, bandwidth, and loocv score.
x <- data[, c("x")]
y <- data[, c("y")]
hat.matrix <- function(bw) t(sapply(x, function(z) Weight(z, bw)))
loocv.score <- function(bw) {
H <- hat.matrix(bw)
yhat <- H%*%y
score <- sum(((y-yhat)/(1-diag(H)))^2)
return (score)
}
if (!is.null(bandwidth)) {
bw <- bandwidth
} else {
bw <- optimize(loocv.score, interval=c(0, max(x)-min(x)))$minimum
}
H <- hat.matrix(bw)
score <- loocv.score(bw)
hat.bw.score <- list(H, bw, score)
return (hat.bw.score)
}
Weight <- function(z, bandwidth, kernel=dnorm) {
# For estimation at point z, gives the Gaussian-smoothed weights that will be
# applied to every x (including itself). This is equivalent to a row of the
# Hat Matrix.
#
# Args:
#   z: Vector of X values to receive weights.
#   bandwidth: A neighborhood around each requested x.star, used to average
#     the area under the smoother function.
#   kernel: The function used to define the type of smoothing around z.
#
# Returns:
#   weight: The weight of the y that corresponds to x.i.
dif <- x-z
weight <- kernel(dif/bandwidth)/bandwidth
s1 <- sum(weight*dif)
s2 <- sum(weight*dif^2)
weight <- weight*(s2-dif*s1)
weight <- weight/sum(weight)
return (weight)
}
CalcResid <- function(data, yhat, H, bw, opt) {
# Calculates and plots residuals for yhat.
#
# Args:
#   data: The full data set.
#   yhat: The predictions generated by multiplying the hat matrix with y.
#   H: The hat matrix.
#   bw: The bandwidth.
#   opt: An optional parameter, used here to pass bootstrapped variances.
#
# Returns:
#   r: Vector of residuals.
x <- data[, c("x")]
y <- data[, c("y")]
n <- length(y)
# Compute residuals for y prediction.
r <- y-yhat
# Compute variance using formula (probably p.6 of Ex3).
if (!is.null(opt)) {
variance <- opt
} else {
variance <- sum(r*r)/(n-2*sum(diag(H))-sum(diag(t(H)%*%H)))
}
se <- sqrt(variance*rowSums(H^2))
# Plot residuals.
plot(x, r, xlab="Temp", ylab="Res. on Avg. Daily Bill",
main=paste("Residuals for Bandwidth =", round(bw, 2)))
# Plot prediction with 95% confidence interval lines.
plot(x, y, col="gray", xlab="Temp", ylab="Y",
main=paste("Local Polynomial Regression with 95% CI, Bandwidth =",
round(bw, 2)))
t <- qt(c(0.025, 0.975), 116)
lines(x, yhat, col="grey20", lwd="2")
lines(x, yhat+t[1]*se, col="dodgerblue3", lwd="2", lty=3)
lines(x, yhat+t[2]*se, col="steelblue1", lwd="2", lty=3)
return (r)
}
# Define available covariance functions, and a helper Delta function.
SqExp <- function(i1, i2, b, t1.sq, t2.sq) {
d <- i2 - i1
val <- t1.sq * exp((-1/2)*(d/b)^2) + (t2.sq)*Delta(i2, i1)
return (val)
}
Matern52 <- function(i1, i2, b, t1.sq, t2.sq) {
d <- sqrt(sum((i2 - i1)^2))
val <- t1.sq*(1 + sqrt(5)*d/b + 5/3*(d^2)/(b^2)) * exp(-sqrt(5)*d/b) + (t2.sq)*Delta(i2, i1)
return (val)
}
LinearPlane <- function(i1, i2, b, t1.sq, t2.sq) {
val <- i1*i2
return (val)
}
Delta <- function(x1, x2) {
ifelse(x1==x2, 1, 0)
}
d <- GetData()
hyperparams <- c(1, 1, 0.000001)
inputs <- d$x
Y <- d$y
kernel <- Matern52
posterior.mean.and.cov <- GaussianProcess(inputs, hyperparams, Matern52, Y)
View(posterior.mean.and.cov)
View(posterior.mean.and.cov)
post.mean <- posterior.mean.and.cov[,1]
post.cov <- posterior.mean.and.cov[,2]
post.data <- data.frame(cbind(inputs, post.mean))
names(post.data) <- c("x", "y")
hbs <- PerformLOOCV(post.data, bandwidth=NULL)
H <- hbs[[1]]
bw <- hbs[[2]]
yhat <- H %*% d$y
r <- CalcResid(post.data, yhat, H, bw, opt=post.cov)
GaussianProcess <- function(inputs, hyperparams, kernel, Y) {
# Runs main operations to perform Gaussian Process (GP), and plots results.
#
# Args:
#   inputs: A vector of scalar points.
#   hyperparams: A vector of three hyperparameters, (b, tau1^2, tau2^2)
#   Y: A flag with Y values, used to add diagonal error variance to
#     covariance matrix, and to compute posterior mean.
#
# Returns:
#   z: The values produced by the Gaussian Process. If Y is provided for
#     posterior mean and covariance, then z is a matrix with a column
#     for posterior mean, and another for posterior covariance.
# Compute covariance matrix and use it to get GP values/output.
c <- Cov(inputs, inputs, hyperparams, kernel)
# ------ Posterior Calculations (Y!=NULL) ------ #
if (!is.null(Y)) {
# Compute K(X,X)+sigsq*I.
error.variance <- diag(rep(var(Y), dim(c)[1]))
c <- c + error.variance
# Make storage for posterior means and covariances.
posterior.mean.and.cov <- matrix(0, nrow=length(inputs), ncol=2)
# For each point, compute posterior mean and covariance.
n <- length(inputs)
for (i in 1:n) {
# Compute posterior mean = K(X*,X) %*% (K(X,X)+sigsq*I)^(-1) %*% y
k.xs.x <- as.matrix(Cov(inputs[i], inputs, hyperparams, kernel))
post.mean.i <- Y[i] + k.xs.x%*%ginv(c)%*%(Y-mean(Y))
post.cov.i <- Cov(inputs[i], inputs[i], hyperparams, kernel) - k.xs.x%*%ginv(c)%*%t(k.xs.x)
posterior.mean.and.cov[i,] <- c(post.mean.i, post.cov.i)
}
z <- posterior.mean.and.cov
return (z)
}
# ------ Regular Calculations (Y=NULL) ------ #
if (is.null(Y)) {
n <- length(inputs)
u <- rnorm(n)
decomp <- svd(c)
z <- decomp$u %*% sqrt(diag(decomp$d)) %*% u
# Plot the output.
plot(inputs, z, main=paste("b=", hyperparams[1],
" t1.sq=", hyperparams[2],
" t2.sq=", hyperparams[3]))
lines(inputs, z)
hist(z, 40)
return (z)
}
}
Cov <- function(ins, inputs, hyperparams, kernel) {
# Computes the covariance of a finite set of points.
#
# Args:
#   ins: The vector of points compared to inputs for covariance.
#   inputs: The vector of scalar points of the data.
#   hyperparams: A vector of three hyperparameters, (b, tau1^2, tau2^2)
#
# Returns:
#   cov.matrix: A symmetrix, positive semi-definite covariance matrix. The
#     dimensions of this matrix are: length(ins) x length(inputs)
b <- hyperparams[1]
t1.sq <- hyperparams[2]
t2.sq <- hyperparams[3]
# Compute covariance with specific covariance function.
cov.matrix <- matrix(NA, nrow=length(ins), ncol=length(inputs))
n1 <- length(ins)
n2 <- length(inputs)
for (i in 1:n1) {
for (j in 1:n2) {
cov.matrix[i, j] <- kernel(ins[i], inputs[j], b, t1.sq, t2.sq)
}
}
return (cov.matrix)
#   cov <- as.matrix(t(sapply(
#     ins, function(k) kernel(k, inputs, b, t1.sq, t2.sq))))
#   return (cov)
}
GetData <- function() {
# Prepares data from file.
#
# Args:
#   NA: None.
#
# Returns:
#   data: A matrix of data.
setwd("~/Google Drive/2. SPRING 2015/STAT MOD 2 - Prof Scott/local polynomial regression")
data <- read.csv("utilities.csv", header=T, sep=",")
# Add column for average daily bill.
data <- within(data, {
y <- gasbill/billingdays
x <- temp
})
data <- data[order(data[, 1]), ]
attach(data)
plot(x, y)
return (data)
}
PerformLOOCV <- function(data, bandwidth) {
# Computes hat matrix and LOOCV score for a given bandwidth; or, if no
# bandwidth is chosen, finds optimal bandwidth (one with lowest LOOCV score)
# and then computes hat matrix.
#
# Args:
#   data: The full data set.
#   bandwidth: The bandwidth for the model. Find optimal by leaving NULL.
#
# Returns:
#   hat.bw.score: A list of hat matrix, bandwidth, and loocv score.
x <- data[, c("x")]
y <- data[, c("y")]
hat.matrix <- function(bw) t(sapply(x, function(z) Weight(z, bw)))
loocv.score <- function(bw) {
H <- hat.matrix(bw)
yhat <- H%*%y
score <- sum(((y-yhat)/(1-diag(H)))^2)
return (score)
}
if (!is.null(bandwidth)) {
bw <- bandwidth
} else {
bw <- optimize(loocv.score, interval=c(0, max(x)-min(x)))$minimum
}
H <- hat.matrix(bw)
score <- loocv.score(bw)
hat.bw.score <- list(H, bw, score)
return (hat.bw.score)
}
Weight <- function(z, bandwidth, kernel=dnorm) {
# For estimation at point z, gives the Gaussian-smoothed weights that will be
# applied to every x (including itself). This is equivalent to a row of the
# Hat Matrix.
#
# Args:
#   z: Vector of X values to receive weights.
#   bandwidth: A neighborhood around each requested x.star, used to average
#     the area under the smoother function.
#   kernel: The function used to define the type of smoothing around z.
#
# Returns:
#   weight: The weight of the y that corresponds to x.i.
dif <- x-z
weight <- kernel(dif/bandwidth)/bandwidth
s1 <- sum(weight*dif)
s2 <- sum(weight*dif^2)
weight <- weight*(s2-dif*s1)
weight <- weight/sum(weight)
return (weight)
}
CalcResid <- function(data, yhat, H, bw, opt) {
# Calculates and plots residuals for yhat.
#
# Args:
#   data: The full data set.
#   yhat: The predictions generated by multiplying the hat matrix with y.
#   H: The hat matrix.
#   bw: The bandwidth.
#   opt: An optional parameter, used here to pass bootstrapped variances.
#
# Returns:
#   r: Vector of residuals.
x <- data[, c("x")]
y <- data[, c("y")]
n <- length(y)
# Compute residuals for y prediction.
r <- y-yhat
# Compute variance using formula (probably p.6 of Ex3).
if (!is.null(opt)) {
variance <- opt
} else {
variance <- sum(r*r)/(n-2*sum(diag(H))-sum(diag(t(H)%*%H)))
}
se <- sqrt(variance*rowSums(H^2))
# Plot residuals.
plot(x, r, xlab="Temp", ylab="Res. on Avg. Daily Bill",
main=paste("Residuals for Bandwidth =", round(bw, 2)))
# Plot prediction with 95% confidence interval lines.
plot(x, y, col="gray", xlab="Temp", ylab="Y",
main=paste("Local Polynomial Regression with 95% CI, Bandwidth =",
round(bw, 2)))
t <- qt(c(0.025, 0.975), 116)
lines(x, yhat, col="grey20", lwd="2")
lines(x, yhat+t[1]*se, col="dodgerblue3", lwd="2", lty=3)
lines(x, yhat+t[2]*se, col="steelblue1", lwd="2", lty=3)
return (r)
}
# Define available covariance functions, and a helper Delta function.
SqExp <- function(i1, i2, b, t1.sq, t2.sq) {
d <- i2 - i1
val <- t1.sq * exp((-1/2)*(d/b)^2) + (t2.sq)*Delta(i2, i1)
return (val)
}
Matern52 <- function(i1, i2, b, t1.sq, t2.sq) {
d <- sqrt(sum((i2 - i1)^2))
val <- t1.sq*(1 + sqrt(5)*d/b + 5/3*(d^2)/(b^2)) * exp(-sqrt(5)*d/b) + (t2.sq)*Delta(i2, i1)
return (val)
}
LinearPlane <- function(i1, i2, b, t1.sq, t2.sq) {
val <- i1*i2
return (val)
}
Delta <- function(x1, x2) {
ifelse(x1==x2, 1, 0)
}
d <- GetData()
hyperparams <- c(10, 1, 0.000001)
inputs <- d$x
Y <- d$y
kernel <- Matern52
posterior.mean.and.cov <- GaussianProcess(inputs, hyperparams, Matern52, Y)
# Do local linear polynomial smoothing.
post.mean <- posterior.mean.and.cov[,1]
post.cov <- posterior.mean.and.cov[,2]
post.data <- data.frame(cbind(inputs, post.mean))
names(post.data) <- c("x", "y")
hbs <- PerformLOOCV(post.data, bandwidth=NULL)
H <- hbs[[1]]
bw <- hbs[[2]]
yhat <- H %*% d$y
r <- CalcResid(post.data, yhat, H, bw, opt=post.cov)
d <- GetData()
hyperparams <- c(0.1, 1, 0.000001)
inputs <- d$x
Y <- d$y
kernel <- Matern52
posterior.mean.and.cov <- GaussianProcess(inputs, hyperparams, Matern52, Y)
# Do local linear polynomial smoothing.
post.mean <- posterior.mean.and.cov[,1]
post.cov <- posterior.mean.and.cov[,2]
post.data <- data.frame(cbind(inputs, post.mean))
names(post.data) <- c("x", "y")
hbs <- PerformLOOCV(post.data, bandwidth=NULL)
H <- hbs[[1]]
bw <- hbs[[2]]
yhat <- H %*% d$y
r <- CalcResid(post.data, yhat, H, bw, opt=post.cov)
d <- GetData()
hyperparams <- c(0.01, 1, 0.000001)
inputs <- d$x
Y <- d$y
kernel <- Matern52
posterior.mean.and.cov <- GaussianProcess(inputs, hyperparams, Matern52, Y)
# Do local linear polynomial smoothing.
post.mean <- posterior.mean.and.cov[,1]
post.cov <- posterior.mean.and.cov[,2]
post.data <- data.frame(cbind(inputs, post.mean))
names(post.data) <- c("x", "y")
hbs <- PerformLOOCV(post.data, bandwidth=NULL)
H <- hbs[[1]]
bw <- hbs[[2]]
yhat <- H %*% d$y
r <- CalcResid(post.data, yhat, H, bw, opt=post.cov)
Main <- function() {
# Runs main functions.
#
# Args:
#   NA: None.
#
# Returns:
#   NA: Plots results.
# ------ Regular Gaussian Processes ------ #
for (i in seq(0.1, 1, 0.3)) {
for (j in seq(0.1, 1, 0.1)) {
par(mfrow=c(2,2))
inputs <- seq(0, 1, 0.01)
hyperparams <- c(i, j, 0.0000001)
z1 <- GaussianProcess(inputs, hyperparams, SqExp, Y=NULL)
z2 <- GaussianProcess(inputs, hyperparams, Matern52, Y=NULL)
#z3 <- GaussianProcess(inputs, hyperparams, LinearPlane, Y=NULL)
}
}
# ------ Gaussian Processes (posterior) Part C - (p.3) ------ #
#par(mfrow=c(2,1))
d <- GetData()
hyperparams <- c(0.01, 1, 0.000001)
inputs <- d$x
Y <- d$y
posterior.mean.and.cov <- GaussianProcess(inputs, hyperparams, Matern52, Y)
# Do local linear polynomial smoothing.
post.mean <- posterior.mean.and.cov[,1]
post.cov <- posterior.mean.and.cov[,2]
post.data <- data.frame(cbind(inputs, post.mean))
names(post.data) <- c("x", "y")
hbs <- PerformLOOCV(post.data, bandwidth=NULL)
H <- hbs[[1]]
bw <- hbs[[2]]
yhat <- H %*% d$y
r <- CalcResid(post.data, yhat, H, bw, opt=post.cov)
}
source('~/Google Drive/2. SPRING 2015/STAT MOD 2 - Prof Scott/gaussian processes/GP-p1-A.R', echo=TRUE)
source('~/Google Drive/2. SPRING 2015/STAT MOD 2 - Prof Scott/gaussian processes/GP-p1-A.R', echo=TRUE)
View(posterior.mean.and.cov)
View(posterior.mean.and.cov)
posterior.mean.and.cov
head(posterior.mean.and.cov)
cbind(d$x, d$y, post.mean, post.cov)
source('~/Google Drive/2. SPRING 2015/STAT MOD 2 - Prof Scott/gaussian processes/GP-p1-A.R', echo=TRUE)
cbind(d$x, d$y, post.mean, post.cov)
